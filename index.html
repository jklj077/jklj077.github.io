<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 4.8.0 for Hugo"><meta name=author content="Xuancheng Ren"><meta name=description content><link rel=alternate hreflang=en-us href=https://jklj077.github.io/><link rel=preconnect href=https://fonts.gstatic.com crossorigin><meta name=theme-color content="#2962ff"><script src=/js/mathjax-config.js></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css crossorigin=anonymous title=hl-light><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css crossorigin=anonymous title=hl-dark disabled><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin=anonymous><script src=https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.2.2/lazysizes.min.js integrity="sha512-TmDwFLhg3UA4ZG0Eb4MIyT1O1Mb+Oww5kFG0uHqXsdbyZz9DcvYQhKpGgNkamAI6h2lGGZq2X8ftOJvF/XjTUg==" crossorigin=anonymous async></script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap"><link rel=stylesheet href=/css/wowchemy.css><link rel=alternate href=/index.xml type=application/rss+xml title="Xuancheng Ren"><link rel=manifest href=/index.webmanifest><link rel=canonical href=https://jklj077.github.io/><meta property="twitter:card" content="summary"><meta property="og:site_name" content="Xuancheng Ren"><meta property="og:url" content="https://jklj077.github.io/"><meta property="og:title" content="Xuancheng Ren"><meta property="og:description" content><meta property="og:image" content="https://jklj077.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png"><meta property="twitter:image" content="https://jklj077.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2021-06-06T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebSite","potentialAction":{"@type":"SearchAction","target":"https://jklj077.github.io/?q={search_term_string}","query-input":"required name=search_term_string"},"url":"https://jklj077.github.io/"}</script><title>Xuancheng Ren</title></head><body id=top data-spy=scroll data-offset=70 data-target=#navbar-main><script>const isSiteThemeDark=false;</script><script src=/js/load-theme.js></script><aside class=search-results id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=#><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Xuancheng Ren</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Xuancheng Ren</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about data-target=#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#publications data-target=#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/project/><span>Projects</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li></ul></div></nav><span class="js-widget-page d-none"></span><section id=about class="home-section wg-about"><div class=container><div class=row><div class="col-12 col-lg-4"><div id=profile><img class="avatar avatar-circle" src=/author/xuancheng-ren/profile_hu521ca6df91c360fce550cd48306f44bf_6157_250x250_fill_lanczos_center_2.png alt="Xuancheng Ren"><div class=portrait-title><h2>Xuancheng Ren</h2><h4><a href=https://lancopku.github.io target=_blank rel=noopener><span>LANCO</span></a></h4><h4><a href=https://icl.pku.edu.cn target=_blank rel=noopener><span>Insititue of Computational Linguistics</span></a></h4><h4><a href=https://eecs.pku.edu.cn target=_blank rel=noopener><span>School of Electronics Engineering and Computer Science</span></a></h4><h4><a href=https://www.pku.edu.cn target=_blank rel=noopener><span>Peking University</span></a></h4></div><ul class=network-icon aria-hidden=true><li><a href=mailto:renxc@pku.edu.cn><i class="fas fa-envelope big-icon"></i></a></li><li><a href=https://github.com/jklj077 target=_blank rel=noopener><i class="fab fa-github big-icon"></i></a></li></ul></div></div><div class="col-12 col-lg-8"><h1>Biography</h1><p>Xuancheng Ren is a graduate student in the School of Electronics Engineering and Computer Science at Peking University, where he is advised by <a href=http://xusun.org target=_blank rel=noopener>Professor Xu Sun</a>. He received the degree of Bachelor of Science in Computer Science from Peking University in 2017.</p><p>His research interests include natural language processing (NLP) and machine learning for NLP. Currently, he works on grounded language processing, which tries to incorporate various sources of knowledge (e.g., vision, commonsense, and semantics) into intelligent systems for reliable and explainable language processing. Previously, he had focused on techniques for efficient deep learning.</p><div class=row><div class=col-md-5><h3>Interests</h3><ul class=ul-interests><li>Natural Language Processing<ul><li>Language Generation</li><li>NLP for Chinese</li></ul></li><li>Machine Learning for NLP</li></ul></div><div class=col-md-7><h3>Education</h3><ul class="ul-edu fa-ul"><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>PhD Candidate in Computer Software and Theory</p><p class=institution>Peking University</p></div></li><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>Bachelor of Science in Computer Science, 2017</p><p class=institution>Peking University</p></div></li></ul></div></div></div></div></div></section><section id=publications class="home-section wg-pages"><div class=container><div class=row><div class="col-12 col-lg-4 section-heading"><h1>Publications</h1></div><div class="col-12 col-lg-8"><div class="media stream-item"><div class=media-body><h3 class="article-title mb-0 mt-0"><a href=/publication/2021naacl-global/>A Global Past-Future Early Exit Method for Accelerating Inference of Pre-trained Language Models</a></h3><a href=/publication/2021naacl-global/ class=summary-link><div class=article-style>Early exit mechanism aims to accelerate inference speed for large-scale pre-trained language models. The essential idea is exiting …</div></a><div class="stream-meta article-metadata"><div class=article-publication-short><strong>NAACL 2021</strong> (to appear)</div><div><span><a href=/author/kaiyuan-liao/>Kaiyuan Liao</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span><a href=/author/yi-zhang/>Yi Zhang</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span class=author-highlighted><a href=/author/xuancheng-ren/>Xuancheng Ren</a></span>, <span><a href=/author/qi-su/>Qi Su</a></span>, <span><a href=/author/xu-sun/>Xu Sun</a></span>, <span><a href=/author/bin-he/>Bin He</a></span></div></div><div class=btn-links><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://github.com/lancopku/Early-Exit target=_blank rel=noopener>Code</a></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><h3 class="article-title mb-0 mt-0"><a href=/publication/2021naacl-careful/>Be Careful about Poisoned Word Embeddings: Exploring the Vulnerability of the Embedding Layers in NLP Models</a></h3><a href=/publication/2021naacl-careful/ class=summary-link><div class=article-style>Recent studies have revealed a security threat to natural language processing (NLP) models, called the Backdoor Attack. Victim models …</div></a><div class="stream-meta article-metadata"><div class=article-publication-short><strong>NAACL 2021</strong> (to appear)</div><div><span><a href=/author/wenkai-yang/>Wenkai Yang</a></span>, <span><a href=/author/lei-li/>Lei Li</a></span>, <span><a href=/author/zhiyuan-zhang/>Zhiyuan Zhang</a></span>, <span class=author-highlighted><a href=/author/xuancheng-ren/>Xuancheng Ren</a></span>, <span><a href=/author/xu-sun/>Xu Sun</a></span>, <span><a href=/author/bin-he/>Bin He</a></span></div></div><div class=btn-links><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://arxiv.org/abs/2103.15543 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://github.com/lancopku/Embedding-Poisoning target=_blank rel=noopener>Code</a></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><h3 class="article-title mb-0 mt-0"><a href=/publication/2021naacl-neural/>Neural Network Surgery: Injecting Data Patterns into Pre-trained Models with Minimal Instance-wise Side Effects</a></h3><a href=/publication/2021naacl-neural/ class=summary-link><div class=article-style>Side effects during neural network tuning are typically measured by overall accuracy changes. However, we find that even with similar …</div></a><div class="stream-meta article-metadata"><div class=article-publication-short><strong>NAACL 2021</strong> (to appear)</div><div><span><a href=/author/zhiyuan-zhang/>Zhiyuan Zhang</a></span>, <span class=author-highlighted><a href=/author/xuancheng-ren/>Xuancheng Ren</a></span>, <span><a href=/author/qi-su/>Qi Su</a></span>, <span><a href=/author/xu-sun/>Xu Sun</a></span>, <span><a href=/author/bin-he/>Bin He</a></span></div></div><div class=btn-links></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><h3 class="article-title mb-0 mt-0"><a href=/publication/2021aaai-collaborative/>Collaborative Group Learning</a></h3><a href=/publication/2021aaai-collaborative/ class=summary-link><div class=article-style>Collaborative learning has successfully applied knowledge transfer to guiding a pool of small student networks towards robust local …</div></a><div class="stream-meta article-metadata"><div class=article-publication-short><strong>AAAI 2021</strong> (to appear)</div><div><span><a href=/author/shaoxiong-feng/>Shaoxiong Feng</a></span>, <span><a href=/author/hongshen-chen/>Hongshen Chen</a></span>, <span class=author-highlighted><a href=/author/xuancheng-ren/>Xuancheng Ren</a></span>, <span><a href=/author/zhouye-ding/>Zhouye Ding</a></span>, <span><a href=/author/kan-li/>Kan Li</a></span>, <span><a href=/author/xu-sun/>Xu Sun</a></span></div></div><div class=btn-links><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://arxiv.org/abs/2009.07712 target=_blank rel=noopener>arXiv</a></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><h3 class="article-title mb-0 mt-0"><a href=/publication/2021aaai-exploring/>Exploring the Vulnerability of Deep Neural Networks: A Study of Parameter Corruption</a></h3><a href=/publication/2021aaai-exploring/ class=summary-link><div class=article-style>We argue that the vulnerability of model parameters is of crucial value to the study of model robustness and generalization but little …</div></a><div class="stream-meta article-metadata"><div class=article-publication-short><strong>AAAI 2021</strong> (to appear)</div><div><span><a href=/author/xu-sun/>Xu Sun</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span><a href=/author/zhiyuan-zhang/>Zhiyuan Zhang</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span class=author-highlighted><a href=/author/xuancheng-ren/>Xuancheng Ren</a></span>, <span><a href=/author/ruixuan-luo/>Ruixuan Luo</a></span>, <span><a href=/author/liangyou-li/>Liangyou Li</a></span></div></div><div class=btn-links><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://www.aaai.org/AAAI21Papers/AAAI-2538.SunX.pdf target=_blank rel=noopener>URL</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://arxiv.org/abs/2006.05620 target=_blank rel=noopener>arXiv</a></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><h3 class="article-title mb-0 mt-0"><a href=/publication/2021aaai-multiview/>Multi-View Feature Representation for Dialogue Generation with Bidirectional Distillation</a></h3><a href=/publication/2021aaai-multiview/ class=summary-link><div class=article-style>Neural dialogue models suffer from low-quality responses when interacted in practice, demonstrating difficulty in generalization over …</div></a><div class="stream-meta article-metadata"><div class=article-publication-short><strong>AAAI 2021</strong> (to appear)</div><div><span><a href=/author/shaoxiong-feng/>Shaoxiong Feng</a></span>, <span class=author-highlighted><a href=/author/xuancheng-ren/>Xuancheng Ren</a></span>, <span><a href=/author/kan-li/>Kan Li</a></span>, <span><a href=/author/xu-sun/>Xu Sun</a></span></div></div><div class=btn-links><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://arxiv.org/abs/2102.10780 target=_blank rel=noopener>arXiv</a></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><h3 class="article-title mb-0 mt-0"><a href=/publication/2021aaai-semantics/>Towards Semantics-Enhanced Pre-Training: Can Lexicon Definitions Help Learning Sentence Meanings?</a></h3><a href=/publication/2021aaai-semantics/ class=summary-link><div class=article-style>Self-supervised pre-training techniques, relying on large amounts of text, have enabled rapid growth in bi-directional language …</div></a><div class="stream-meta article-metadata"><div class=article-publication-short><strong>AAAI 2021</strong> (to appear)</div><div><span class=author-highlighted><a href=/author/xuancheng-ren/>Xuancheng Ren</a></span>, <span><a href=/author/xu-sun/>Xu Sun</a></span>, <span><a href=/author/houfeng-wang/>Houfeng Wang</a></span>, <span><a href=/author/qun-liu/>Qun Liu</a></span></div></div><div class=btn-links><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://www.aaai.org/AAAI21Papers/AAAI-9726.RenX.pdf target=_blank rel=noopener>URL</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://github.com/lancopku/sempre target=_blank rel=noopener>Code</a></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><h3 class="article-title mb-0 mt-0"><a href=/publication/2020neurips-prophet/>Prophet Attention: Predicting Attention with Future Attention for Improved Image Captioning</a></h3><a href=/publication/2020neurips-prophet/ class=summary-link><div class=article-style>Recently, attention based models have been used extensively in image captioning and are expected to ground correct image regions with …</div></a><div class="stream-meta article-metadata"><div class=article-publication-short><strong>NeurIPS 2020</strong> (to appear)</div><div><span><a href=/author/fenglin-liu/>Fenglin Liu</a></span>, <span class=author-highlighted><a href=/author/xuancheng-ren/>Xuancheng Ren</a></span>, <span><a href=/author/xian-wu/>Xian Wu</a></span>, <span><a href=/author/shen-ge/>Shen Ge</a></span>, <span><a href=/author/wei-fan/>Wei Fan</a></span>, <span><a href=/author/yuexian-zou/>Yuexian Zou</a></span>, <span><a href=/author/xu-sun/>Xu Sun</a></span></div></div><div class=btn-links><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://proceedings.neurips.cc/paper/2020/hash/13fe9d84310e77f13a6d184dbf1232f3-Abstract.html target=_blank rel=noopener>URL</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/publication/2020neurips-prophet/cite.bib>
Cite</button></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><h3 class="article-title mb-0 mt-0"><a href=/publication/2020emnlp-regularizing/>Regularizing Dialogue Generation by Imitating Implicit Scenarios</a></h3><a href=/publication/2020emnlp-regularizing/ class=summary-link><div class=article-style>Human dialogues are scenario-based and appropriate responses generally relate to the latent context knowledge entailed by the specific …</div></a><div class="stream-meta article-metadata"><div class=article-publication-short><strong>EMNLP 2020</strong></div><div><span><a href=/author/shaoxiong-feng/>Shaoxiong Feng</a></span>, <span class=author-highlighted><a href=/author/xuancheng-ren/>Xuancheng Ren</a></span>, <span><a href=/author/hongshen-chen/>Hongshen Chen</a></span>, <span><a href=/author/bin-sun/>Bin Sun</a></span>, <span><a href=/author/kan-li/>Kan Li</a></span>, <span><a href=/author/xu-sun/>Xu Sun</a></span></div></div><div class=btn-links><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://www.aclweb.org/anthology/2020.emnlp-main.534/ target=_blank rel=noopener>URL</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/publication/2020emnlp-regularizing/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.18653/v1/2020.emnlp-main.534 target=_blank rel=noopener>DOI</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://arxiv.org/abs/2010.01893 target=_blank rel=noopener>arXiv</a></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><h3 class="article-title mb-0 mt-0"><a href=/publication/2019neurips-aligning/>Aligning Visual Regions and Textual Concepts for Semantic-Grounded Image Representations</a></h3><a href=/publication/2019neurips-aligning/ class=summary-link><div class=article-style>In vision-and-language grounding problems, fine-grained representations of the image are considered to be of paramount importance. Most …</div></a><div class="stream-meta article-metadata"><div class=article-publication-short><strong>NeurIPS 2019</strong></div><div><span><a href=/author/fenglin-liu/>Fenglin Liu</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span><a href=/author/yuanxin-liu/>Yuanxin Liu</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span class=author-highlighted><a href=/author/xuancheng-ren/>Xuancheng Ren</a></span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span><a href=/author/xiaodong-he/>Xiaodong He</a></span>, <span><a href=/author/xu-sun/>Xu Sun</a></span></div></div><div class=btn-links><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://papers.nips.cc/paper/8909-aligning-visual-regions-and-textual-concepts-for-semantic-grounded-image-representations target=_blank rel=noopener>URL</a>
<button type=button class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal" data-filename=/publication/2019neurips-aligning/cite.bib>
Cite</button>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://arxiv.org/abs/1905.06139 target=_blank rel=noopener>arXiv</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://github.com/fenglinliu98/MIA target=_blank rel=noopener>Code</a></div></div><div class=ml-3><a href=/publication/2019neurips-aligning/><img src=/publication/2019neurips-aligning/featured_hu0c428725cb9fc1d4297737f2d1e370a6_694615_150x0_resize_lanczos_2.png alt="Aligning Visual Regions and Textual Concepts for Semantic-Grounded Image Representations"></a></div></div><div class=see-all><a href=/publication/>See all publications
<i class="fas fa-angle-right"></i></a></div></div></div></div></section><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin=anonymous></script><script>const code_highlighting=true;</script><script>const search_config={"indexURI":"/index.json","minLength":1,"threshold":0.3};const i18n={"no_results":"No results found","placeholder":"Search...","results":"results found"};const content_type={'post':"Posts",'project':"Projects",'publication':"Publications",'talk':"Talks",'slides':"Slides"};</script><script id=search-hit-fuse-template type=text/x-template>
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script><script src=/js/wowchemy.min.4c2bca31150ce93c5a5e43b8a50f22fd.js></script><div class=container><footer class=site-footer><p class=powered-by>© 2021 Xuancheng Ren</p><p class=powered-by>Published with
<a href=https://wowchemy.com target=_blank rel=noopener>Wowchemy</a> —
the free, <a href=https://github.com/wowchemy/wowchemy-hugo-modules target=_blank rel=noopener>open source</a> website builder that empowers creators.
<span class=float-right aria-hidden=true><a href=# class=back-to-top><span class=button_icon><i class="fas fa-chevron-up fa-2x"></i></span></a></span></p></footer></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i>Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i>Download</a><div id=modal-error></div></div></div></div></div></body></html>