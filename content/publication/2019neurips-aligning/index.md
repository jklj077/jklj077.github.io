---
title: "Aligning Visual Regions and Textual Concepts for Semantic-Grounded Image Representations"
date: 2019-12-08
publishDate: 2019-12-23T08:04:29.940124Z
authors: ["Fenglin Liu", "Yuanxin Liu", "admin", "Xiaodong He", "Xu Sun"]
author_notes:
- "Equal contribution"
- "Equal contribution"
- "Equal contribution"
publication_types: ["1"]
abstract: "In vision-and-language grounding problems, fine-grained representations of the image are considered to be of paramount importance. Most of the current systems incorporate visual features and textual concepts as a sketch of an image. However, plainly inferred representations are usually undesirable in that they are composed of separate components, the relations of which are elusive. In this work, we aim at representing an image with a set of integrated visual regions and corresponding textual concepts, reflecting certain semantics. To this end, we build the Mutual Iterative Attention (MIA) module, which integrates correlated visual features and textual concepts, respectively, by aligning the two modalities. We evaluate the proposed approach on two representative vision-and-language grounding tasks, i.e., image captioning and visual question answering. In both tasks, the semantic-grounded image representations consistently boost the performance of the baseline models under all metrics across the board. The results demonstrate that our approach is effective and generalizes well to a wide range of models for image-related applications."
featured: true
publication: "*Advances in Neural Information Processing Systems 32 (**NeurIPS 2019**)*"
publication_short: "**NeurIPS 2019**"
url_pdf: "https://papers.nips.cc/paper/8909-aligning-visual-regions-and-textual-concepts-for-semantic-grounded-image-representations"
url_arxiv: "https://arxiv.org/abs/1905.06139"
url_code: "https://github.com/fenglinliu98/MIA"


# Featured image
# To use, place an image named `featured.jpg/png` in your page's folder.
# Placement options: 1 = Full column width, 2 = Out-set, 3 = Screen-width
# Focal point options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
# Set `preview_only` to `true` to just use the image for thumbnails.
image:
  placement: 1
  caption: "Visualization of the integrated image representations. We show the representations with different iteration N for two images. We choose three visual features and corresponding textual concepts with clear semantic implication and highlight them with distinct colors. As we see, with N increasing, the alignment becomes more focused and more specific, but the combination of related features are less represented."
  focal_point: "Smart"
  preview_only: false
---

