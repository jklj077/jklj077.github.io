[{"authors":["admin"],"categories":null,"content":"Xuancheng Ren is a graduate student in the School of Electronics Engineering and Computer Science at Peking University, where he is advised by Professor Xu Sun. He received the degree of Bachelor of Science in Computer Science from Peking University in 2017.\nHis research interests include natural language processing (NLP) and machine learning for NLP. Currently, he works on grounded language processing, which tries to incorporate various sources of knowledge (e.g., vision, commonsense, and semantics) into intelligent systems for reliable and explainable language processing. Previously, he had focused on techniques for efficient deep learning.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1607083736,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://jklj077.github.io/author/xuancheng-ren/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/xuancheng-ren/","section":"authors","summary":"Xuancheng Ren is a graduate student in the School of Electronics Engineering and Computer Science at Peking University, where he is advised by Professor Xu Sun. He received the degree of Bachelor of Science in Computer Science from Peking University in 2017.","tags":null,"title":"Xuancheng Ren","type":"authors"},{"authors":["Kaiyuan Liao","Yi Zhang","Xuancheng Ren","Qi Su","Xu Sun","Bin He"],"categories":[],"content":"","date":1622937600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617883830,"objectID":"03298d3c2e3818657abd011effe6584d","permalink":"https://jklj077.github.io/publication/2021naacl-global/","publishdate":"2020-12-01T12:57:44+08:00","relpermalink":"/publication/2021naacl-global/","section":"publication","summary":"Early exit mechanism aims to accelerate inference speed for large-scale pre-trained language models. The essential idea is exiting early without passing through all the inference layers at the inference stage. To make accurate predictions for downstream tasks, the hierarchical linguistic information embedded in all layers should be jointly considered. However, much of the research up to now has been limited to use local representations of the exit layer. Such treatment inevitably loses information of the unused passed layers as well as the high-level features embedded in future layers, leading to sub-optimal performance. To address this issue, we propose a novel Past-Future method to make comprehensive predictions from a global perspective. We first take into consideration all the hierarchical linguistic information embedded in the past layers and then take a further step to engage the future states which are originally inaccessible for predictions. Extensive experiments demonstrate that our method outperforms previous early exit methods by a large margin, yielding more effective and more robust results.","tags":[],"title":"A Global Past-Future Early Exit Method for Accelerating Inference of Pre-trained Language Models","type":"publication"},{"authors":["Wenkai Yang","Lei Li","Zhiyuan Zhang","Xuancheng Ren","Xu Sun","Bin He"],"categories":[],"content":"","date":1622937600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617885013,"objectID":"f4a63933bba4516346754cc897a3c475","permalink":"https://jklj077.github.io/publication/2021naacl-careful/","publishdate":"2020-12-01T12:53:44+08:00","relpermalink":"/publication/2021naacl-careful/","section":"publication","summary":"Recent studies have revealed a security threat to natural language processing (NLP) models, called the Backdoor Attack. Victim models can maintain competitive performance on clean samples while behaving abnormally on samples with a specific trigger word inserted. Previous backdoor attacking methods usually assume that attackers have a certain degree of data knowledge, either the dataset which users would use or proxy datasets for a similar task, for implementing the data poisoning procedure. However, in this paper, we find that it is possible to hack the model in a data-free way by modifying one single word embedding vector, with almost no accuracy sacrificed on clean samples. Experimental results on sentiment analysis and sentence-pair classification tasks show that our method is more efficient and stealthier. We hope this work can raise the awareness of such a critical security risk hidden in the embedding layers of NLP models.","tags":[],"title":"Be Careful about Poisoned Word Embeddings: Exploring the Vulnerability of the Embedding Layers in NLP Models","type":"publication"},{"authors":["Zhiyuan Zhang","Xuancheng Ren","Qi Su","Xu Sun","Bin He"],"categories":[],"content":"","date":1622937600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617883830,"objectID":"6b3d49b1f89cda1a5169fe9e3e45636e","permalink":"https://jklj077.github.io/publication/2021naacl-neural/","publishdate":"2020-12-01T12:57:45+08:00","relpermalink":"/publication/2021naacl-neural/","section":"publication","summary":"Side effects during neural network tuning are typically measured by overall accuracy changes. However, we find that even with similar overall accuracy, existing tuning methods result in non-negligible instance-wise side effects. Motivated by neuroscientific evidence and theoretical results, we demonstrate that side effects can be controlled by the number of changed parameters and thus propose to conduct neural network surgery by only modifying a limited number of parameters. Neural network surgery can be realized using diverse techniques, and we investigate three lines of methods. Experimental results on representative tuning problems validate the effectiveness of the surgery approach. The dynamic selecting method achieves the best overall performance that not only satisfies the tuning goal but also induces fewer instance-wise side effects by changing only 10^-5 of the parameters.","tags":[],"title":"Neural Network Surgery: Injecting Data Patterns into Pre-trained Models with Minimal Instance-wise Side Effects","type":"publication"},{"authors":["Shaoxiong Feng","Hongshen Chen","Xuancheng Ren","Zhouye Ding","Kan Li","Xu Sun"],"categories":[],"content":"","date":1612224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617883830,"objectID":"07bd4b9e39144f59423bc9d09d1673dc","permalink":"https://jklj077.github.io/publication/2021aaai-collaborative/","publishdate":"2020-12-02T12:57:23+08:00","relpermalink":"/publication/2021aaai-collaborative/","section":"publication","summary":"Collaborative learning has successfully applied knowledge transfer to guiding a pool of small student networks towards robust local minima. However, previous approaches typically struggle with drastically aggravated student homogenization when the number of students rises. In this paper, we propose Collaborative Group Learning, an efficient framework that aims to diversify the feature representation and conduct an effective regularization. Intuitively, similar to the human group study mechanism, we induce students to learn and exchange different parts of course knowledge as collaborative groups. First, each student is established by randomly routing on a modular neural network, which facilitates flexible knowledge communication between students due to random levels of representation sharing and branching. Second, to resist the student homogenization, students first compose diverse feature sets by exploiting the inductive bias from sub-sets of training data, and then aggregate and distill different complementary knowledge by imitating a random sub-group of students at each time step. Besides, the above mechanisms are beneficial for maximizing the student population to further improve the model generalization without sacrificing computational efficiency. Empirical evaluations on both image and text tasks indicate that our method significantly outperforms various state-of-the-art collaborative approaches whilst enhancing computational efficiency.","tags":[],"title":"Collaborative Group Learning","type":"publication"},{"authors":["Xu Sun","Zhiyuan Zhang","Xuancheng Ren","Ruixuan Luo","Liangyou Li"],"categories":[],"content":"","date":1612224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617883830,"objectID":"e90faab69cc53c66502a9f90f6d27d3b","permalink":"https://jklj077.github.io/publication/2021aaai-exploring/","publishdate":"2020-12-02T12:57:00+08:00","relpermalink":"/publication/2021aaai-exploring/","section":"publication","summary":"We argue that the vulnerability of model parameters is of crucial value to the study of model robustness and generalization but little research has been devoted to understanding this matter. In this work, we propose an indicator to measure the robustness of neural network parameters by exploiting their vulnerability via parameter corruption. The proposed indicator describes the maximum loss variation in the non-trivial worst-case scenario under parameter corruption. For practical purposes, we give a gradient-based estimation, which is far more effective than random corruption trials that can hardly induce the worst accuracy degradation. Equipped with theoretical support and empirical validation, we are able to systematically investigate the robustness of different model parameters and reveal vulnerability of deep neural networks that has been rarely paid attention to before. Moreover, we can enhance the models accordingly with the proposed adversarial corruption-resistant training, which not only improves the parameter robustness but also translates into accuracy elevation.","tags":[],"title":"Exploring the Vulnerability of Deep Neural Networks: A Study of Parameter Corruption","type":"publication"},{"authors":["Shaoxiong Feng","Xuancheng Ren","Kan Li","Xu Sun"],"categories":[],"content":"","date":1612224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617883830,"objectID":"f06579aebab4aebbb15eb30f5084cacc","permalink":"https://jklj077.github.io/publication/2021aaai-multiview/","publishdate":"2020-12-02T12:57:33+08:00","relpermalink":"/publication/2021aaai-multiview/","section":"publication","summary":"Neural dialogue models suffer from low-quality responses when interacted in practice, demonstrating difficulty in generalization over training data. Recently, knowledge distillation has been used to successfully regularize the student by transferring knowledge from the teacher. However, the teacher and the student are trained on the same dataset and tend to learn similar feature representations, whereas the most general knowledge should be found through differences. The finding of general knowledge is further hindered by the unidirectional distillation, as the student should obey the teacher and may discard some knowledge that is truly general but refuted by the teacher. To this end, we propose a novel training framework, where the learning of general knowledge is more in line with the idea of reaching consensus, i.e., finding common knowledge that is beneficial to different yet all datasets through diversified learning partners. Concretely, the training task is divided into a group of subtasks with the same number of students. Each student assigned to one subtask is not only optimized on the allocated subtask but also imitates multi-view feature representation aggregated from other students (i.e., student peers), which induces students to capture common knowledge among different subtasks and alleviates the over-fitting of students on the allocated subtasks. To further enhance generalization, we extend the unidirectional distillation to the bidirectional distillation that encourages the student and its student peers to co-evolve by exchanging complementary knowledge with each other. Empirical results and analysis demonstrate that our training framework effectively improves the model generalization without sacrificing training efficiency.","tags":[],"title":"Multi-View Feature Representation for Dialogue Generation with Bidirectional Distillation","type":"publication"},{"authors":["Xuancheng Ren","Xu Sun","Houfeng Wang","Qun Liu"],"categories":[],"content":"","date":1612224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617883830,"objectID":"65c3dcc3347079d04a76b07394619fea","permalink":"https://jklj077.github.io/publication/2021aaai-semantics/","publishdate":"2020-12-02T12:57:44+08:00","relpermalink":"/publication/2021aaai-semantics/","section":"publication","summary":"Self-supervised pre-training techniques, relying on large amounts of text, have enabled rapid growth in bi-directional language representations for natural language understanding. However, as empirical models on sentences, they are subject to the input data distribution, inevitably incorporating data bias and reporting bias, which may lead to inaccurate understanding of sentences. To address the problem, we propose to adopt the human learner's approach: when we cannot make sense of a word, we often consult the dictionary for specific meanings; but can the same work for empirical models? In this work, we try to inform the pre-trained models of word meanings for a further semantics-enhanced pre-training. To achieve a contrastive and holistic view of word meanings, a definition pair of two related words is presented to the masked language model such that the model can better associate a word with its crucial semantic features. Both intrinsic and extrinsic evaluation validates the proposed approach on semantics-orientated tasks, with an almost negligible increase of training data.","tags":[],"title":"Towards Semantics-Enhanced Pre-Training: Can Lexicon Definitions Help Learning Sentence Meanings?","type":"publication"},{"authors":["Fenglin Liu","Xuancheng Ren","Xian Wu","Shen Ge","Wei Fan","Yuexian Zou","Xu Sun"],"categories":null,"content":"","date":1607299200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617883830,"objectID":"3d652acb63f512525c2522d1578d4573","permalink":"https://jklj077.github.io/publication/2020neurips-prophet/","publishdate":"2020-09-26T08:04:29.940124Z","relpermalink":"/publication/2020neurips-prophet/","section":"publication","summary":"Recently, attention based models have been used extensively in image captioning and are expected to ground correct image regions with proper generated words. However, for each time step in the decoding process, the attention based models usually use the hidden state of current input to attend to the image regions. Under this setting, these attention models have a “deviated focus” problem, that they calculate the attention weights based on previous words instead of the one to be generated, impairing the performance of both grounding and captioning. In this paper, we propose the Prophet Attention, similar to the form of self-supervision. In the training stage, this module utilizes the future information to calculate the “ideal” attention weights towards image regions. These calculated weights are further used to regularize the “deviated” attention. In this manner, image regions are grounded with the correct words. Prophet Attention does not introduce additional model parameters or inference computations, making it easily incorporated into any existing systems. The experiments on the Flickr30k Entities and MSCOCO datasets show that the proposed Prophet Attention consistently outperforms baselines in both automatic metrics and human evaluations. It is worth noticing that we set new state-of-the-arts on the two benchmark datasets and achieve the 1st place on the leaderboard of the online MSCOCO benchmark.","tags":null,"title":"Prophet Attention: Predicting Attention with Future Attention for Improved Image Captioning","type":"publication"},{"authors":["Shaoxiong Feng","Xuancheng Ren","Hongshen Chen","Bin Sun","Kan Li","Xu Sun"],"categories":null,"content":"","date":1605484800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617885013,"objectID":"405ba6ef30908b67691d6c014a9a4286","permalink":"https://jklj077.github.io/publication/2020emnlp-regularizing/","publishdate":"2020-09-30T15:30:29.98113Z","relpermalink":"/publication/2020emnlp-regularizing/","section":"publication","summary":"Human dialogues are scenario-based and appropriate responses generally relate to the latent context knowledge entailed by the specific scenario. To enable responses that are more meaningful and context-specific, we propose to improve generative dialogue systems from the scenario perspective, where both dialogue history and future conversation are taken into account to implicitly reconstruct the scenario knowledge. More importantly, the conversation scenarios are further internalized using imitation learning framework, where the conventional dialogue model that has no access to future conversations is effectively regularized by transferring the scenario knowledge contained in hierarchical supervising signals from the scenario-based dialogue model, so that the future conversation is not required in actual inference. Extensive evaluations show that our approach significantly outperforms state-of-the-art baselines on diversity and relevance, and expresses scenario-specific knowledge.","tags":null,"title":"Regularizing Dialogue Generation by Imitating Implicit Scenarios","type":"publication"},{"authors":["Fenglin Liu","Yuanxin Liu","Xuancheng Ren","Xiaodong He","Xu Sun"],"categories":null,"content":"","date":1575763200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611657712,"objectID":"f8ecd3f771b4023ff4d8d20548fdb23d","permalink":"https://jklj077.github.io/publication/2019neurips-aligning/","publishdate":"2019-12-23T08:04:29.940124Z","relpermalink":"/publication/2019neurips-aligning/","section":"publication","summary":"In vision-and-language grounding problems, fine-grained representations of the image are considered to be of paramount importance. Most of the current systems incorporate visual features and textual concepts as a sketch of an image. However, plainly inferred representations are usually undesirable in that they are composed of separate components, the relations of which are elusive. In this work, we aim at representing an image with a set of integrated visual regions and corresponding textual concepts, reflecting certain semantics. To this end, we build the Mutual Iterative Attention (MIA) module, which integrates correlated visual features and textual concepts, respectively, by aligning the two modalities. We evaluate the proposed approach on two representative vision-and-language grounding tasks, i.e., image captioning and visual question answering. In both tasks, the semantic-grounded image representations consistently boost the performance of the baseline models under all metrics across the board. The results demonstrate that our approach is effective and generalizes well to a wide range of models for image-related applications.","tags":null,"title":"Aligning Visual Regions and Textual Concepts for Semantic-Grounded Image Representations","type":"publication"},{"authors":["Fenglin Liu","Xuancheng Ren","Yuanxin Liu","Kai Lei","Xu Sun"],"categories":null,"content":"","date":1565395200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611657712,"objectID":"49ad0b2600a1bb4a49c1158995bbdc22","permalink":"https://jklj077.github.io/publication/2019ijcai-exploring/","publishdate":"2019-12-23T08:04:29.924123Z","relpermalink":"/publication/2019ijcai-exploring/","section":"publication","summary":"Recently, attention-based encoder-decoder models have been used extensively in image captioning. Yet there is still great difficulty for the current methods to achieve deep image understanding. In this work, we argue that such understanding requires visual attention to correlated image regions and semantic attention to coherent attributes of interest. To perform effective attention, we explore image captioning from a cross-modal perspective and propose the Global-and-Local Information Exploring-and-Distilling approach that explores and distills the source information in vision and language. It globally provides the aspect vector, a spatial and relational representation of images based on caption contexts, through the extraction of salient region groupings and attribute collocations, and locally extracts the fine-grained regions and attributes in reference to the aspect vector for word selection. Our fully-attentive model achieves a CIDEr score of 129.3 in offline COCO evaluation with remarkable efficiency in terms of accuracy, speed, and parameter budget.","tags":null,"title":"Exploring and Distilling Cross-Modal Information for Image Captioning","type":"publication"},{"authors":["Chen Wu","Xuancheng Ren","Fuli Luo","Xu Sun"],"categories":null,"content":"","date":1564704000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611657712,"objectID":"df62011ee00d812d915f234b93d3a106","permalink":"https://jklj077.github.io/publication/2019acl-hierarchical/","publishdate":"2019-12-23T08:04:29.921124Z","relpermalink":"/publication/2019acl-hierarchical/","section":"publication","summary":"Unsupervised text style transfer aims to alter text styles while preserving the content, without aligned data for supervision. Existing seq2seq methods face three challenges: 1) the transfer is weakly interpretable, 2) generated outputs struggle in content preservation, and 3) the trade-off between content and style is intractable. To address these challenges, we propose a hierarchical reinforced sequence operation method, named Point-Then-Operate (PTO), which consists of a high-level agent that proposes operation positions and a low-level agent that alters the sentence. We provide comprehensive training objectives to control the fluency, style, and content of the outputs and a mask-based inference algorithm that allows for multi-step revision based on the single-step trained agents. Experimental results on two text style transfer datasets show that our method significantly outperforms recent methods and effectively addresses the aforementioned challenges.","tags":null,"title":"A Hierarchical Reinforced Sequence Operation Method for Unsupervised Text Style Transfer","type":"publication"},{"authors":["Ruixuan Luo","Jingjing Xu","**Xuancheng Ren**","Yi Zhang","Bingzhen Wei","Xu Sun"],"categories":[],"content":"PKUSeg-python is a multi-domain Chinese word segmentation toolkit in Python. There is also a C# version of this toolkit, in which I am not involved.\nHighlights The toolkit has the following features:\n  Supporting multi-domain Chinese word segmentation. PKUSeg-python supports multi-domain segmentation, including domains like news, web, medicine, and tourism. Users are free to choose different pre-trained models according to the domain features of the text to be segmented. If not sure the domain of the text, users are recommended to use the default model trained on mixed-domain data.\n  Higher word segmentation results. Compared with existing word segmentation toolkits, pkuseg-python can achieve higher F1 scores on the same dataset.\n  Supporting model training. PKUSeg-python also supports users to train a new segmentation model with their own data.\n  Supporting POS tagging. We also provide users POS tagging interfaces for further lexical analysis.\n  Work I have mainly worked on improving the efficiency and the maintainability of the toolkit:\n Identify the bottleneck of speed Rework the core compuation parts with Cython, bringing ~9x speedup Refactor the codes and address backward compatibility  ","date":1561646553,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577159423,"objectID":"fa633aa700d8a6631dd55d2c44c25c41","permalink":"https://jklj077.github.io/project/pkuseg/","publishdate":"2019-06-27T22:42:33+08:00","relpermalink":"/project/pkuseg/","section":"project","summary":"PKUSeg-python is a multi-domain Chinese word segmentation toolkit in Python. There is also a C# version of this toolkit, in which I am not involved.\nHighlights The toolkit has the following features:","tags":[],"title":"PKUSeg","type":"project"},{"authors":["Ruixuan Luo","Jingjing Xu","Yi Zhang","Xuancheng Ren","Xu Sun"],"categories":null,"content":"","date":1561593600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611657712,"objectID":"212e7ffb06ac6dde3f59ec2cfa87c285","permalink":"https://jklj077.github.io/publication/2019techreport-pkuseg/","publishdate":"2019-12-23T08:04:29.951128Z","relpermalink":"/publication/2019techreport-pkuseg/","section":"publication","summary":"Chinese word segmentation (CWS) is a fundamental step of Chinese natural language processing. In this paper, we build a new toolkit, named PKUSEG, for multi-domain word segmentation. Unlike existing single-model toolkits, PKUSEG targets at multi-domain word segmentation and provides separate models for different domains, such as web, medicine, and tourism. The new toolkit also supports POS tagging and model training to adapt to various application scenarios. Experiments show that PKUSEG achieves high performance on multiple domains. The toolkit is now freely and publicly available for the usage of research and industry.","tags":null,"title":"PKUSEG: A Toolkit for Multi-Domain Chinese Word Segmentation","type":"publication"},{"authors":["Xu Sun","Shuming Ma","Yi Zhang","Xuancheng Ren"],"categories":null,"content":"","date":1554076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611657712,"objectID":"ebf8877c433fade694a70396d2f3d056","permalink":"https://jklj077.github.io/publication/2019isci-easier/","publishdate":"2019-12-23T08:04:29.914123Z","relpermalink":"/publication/2019isci-easier/","section":"publication","summary":"There are two major approaches for sequence labeling. One is the probabilistic gradient-based methods such as conditional random fields (CRF) and neural networks (e.g., RNN), which have high accuracy but drawbacks: slow training, and no support of search-based optimization (which is important in many cases). The other is the search-based learning methods such as structured perceptron and margin infused relaxed algorithm (MIRA), which have fast training but also drawbacks: low accuracy, no probabilistic information, and non-convergence in real-world tasks. We propose a novel and “easy” solution, a search-based probabilistic online learning method, to address most of those issues. The method is “easy”, because the optimization algorithm at the training stage is as simple as the decoding algorithm at the test stage. This method searches the output candidates, derives probabilities, and conducts efficient online learning. We show that this method with fast training and theoretical guarantee of convergence, which is easy to implement, can support search-based optimization and obtain top accuracy. Experiments on well-known tasks show that our method has better accuracy than CRF and BiLSTM.","tags":null,"title":"Towards Easier and Faster Sequence Labeling for Natural Language Processing: A Search-Based Probabilistic Online Learning Framework (SAPO)","type":"publication"},{"authors":["Xu Sun","Xuancheng Ren","Shuming Ma","Bingzhen Wei","Wei Li","Jingjing Xu","Houfeng Wang","Yi Zhang"],"categories":null,"content":"","date":1543276800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611657712,"objectID":"75e67299b0662f732773b9459aa7813c","permalink":"https://jklj077.github.io/publication/2018tkde-training/","publishdate":"2019-12-23T08:04:30.047125Z","relpermalink":"/publication/2018tkde-training/","section":"publication","summary":"We propose a simple yet effective technique to simplify the training and the resulting model of neural networks. In back propagation, only a small subset of the full gradient is computed to update the model parameters. The gradient vectors are sparsified in such a way that only the top-k elements (in terms of magnitude) are kept. As a result, only k rows or columns (depending on the layout) of the weight matrix are modified, leading to a linear reduction in the computational cost. Based on the sparsified gradients, we further simplify the model by eliminating the rows or columns that are seldom updated, which will reduce the computational cost both in the training and decoding, and potentially accelerate decoding in real-world applications. Surprisingly, experimental results demonstrate that most of time we only need to update fewer than 5% of the weights at each back propagation pass. More interestingly, the accuracy of the resulting models is actually improved rather than degraded, and a detailed analysis is given. The model simplification results show that we could adaptively simplify the model which could often be reduced by around 9x, without any loss on accuracy or even with improved accuracy.","tags":null,"title":"Training Simplification and Model Simplification for Deep Learning: A Minimal Effort Back Propagation Method","type":"publication"},{"authors":["Jingjing Xu","Hangfeng He","Xu Sun","Xuancheng Ren","Sujian Li"],"categories":null,"content":"","date":1541030400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611657712,"objectID":"909801e02e054330a6c13cd3a4b9b564","permalink":"https://jklj077.github.io/publication/2018taslp-cross/","publishdate":"2019-12-23T08:04:29.960124Z","relpermalink":"/publication/2018taslp-cross/","section":"publication","summary":"Named entity recognition (NER) in Chinese social media is an important, but challenging task because Chinese social media language is informal and noisy. Most previous methods on NER focus on in-domain supervised learning, which is limited by scarce annotated data in social media. In this paper, we present that sufficient corpora in formal domains and massive unannotated text can be combined to improve the NER performance in social media. We propose a unified model which can learn from out-of-domain corpora and in-domain unannotated text. The unified model is composed of two parts. One is for cross-domain learning and the other is for semisupervised learning. Cross-domain learning can learn out-of-domain information based on domain similarity. Semisupervised learning can learn in-domain unannotated information by self-training. Experimental results show that our unified model yields a 9.57% improvement over strong baselines and achieves the state-of-the-art performance.","tags":null,"title":"Cross-Domain and Semisupervised Named Entity Recognition in Chinese Social Media: A Unified Model","type":"publication"},{"authors":["Ruixuan Luo","**Xuancheng Ren**","Junyang Lin","Jingjing Xu","Xu Sun"],"categories":[],"content":"JDDC stands for JD Dialog Challenge, which is a task-oriented multi-turn dialogue challenge in the e-commerce setup. We participated in the 2018 edition of this challenge.\nHighlights We design a novel system based on mixed response proposal.\n A classification module based on fully-connected neural network using bag-of-words is first used to dispatch the coming questions, either for answer retrieving or for answer generation. For answer retrieving, common questions are directly mapped to the corresponding answer pool and an answer is randomly selected. The answer pool is generated based on the clusterd questions in terms of semantic similarity. For answer generation, other questions are given to a history-based sequence-to-sequence neural network, and a never-before-seen answer is generated based on beam search.  The proposed system works fine for practical purpose:\n It achieves a good balance between speed and accuarcy. Surprisingly, we did not use the related product knowledge but answered most of the questions very well. We won the first place in the automatic evaluation and were second to the based in the human evaluation. In addition, we were given the Architecture Innovation Award and the Excellent Instructor Award was given to Prof. Xu Sun.  Work I joined the team in the second phase of the competition and was responsible for refining, exploring, and verifying the new system design. Besides, I worked the design/technical documents and presentation slides and particated in the final defense, with Junyang Lin and Ruixuan Luo.\n","date":1540996965,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577116072,"objectID":"691201bbad08280d4df561d3189100a1","permalink":"https://jklj077.github.io/project/jddc/","publishdate":"2018-10-31T22:42:45+08:00","relpermalink":"/project/jddc/","section":"project","summary":"JDDC stands for JD Dialog Challenge, which is a task-oriented multi-turn dialogue challenge in the e-commerce setup. We participated in the 2018 edition of this challenge.\nHighlights We design a novel system based on mixed response proposal.","tags":[],"title":"JDDC 2018","type":"project"},{"authors":["Jingjing Xu","Xuancheng Ren","Yi Zhang","Qi Zeng","Xiaoyan Cai","Xu Sun"],"categories":null,"content":"","date":1540944000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611657712,"objectID":"ea5068b293f5943db8e7c85f0ca6dd0a","permalink":"https://jklj077.github.io/publication/2018emnlp-skeleton/","publishdate":"2019-12-23T08:04:29.98113Z","relpermalink":"/publication/2018emnlp-skeleton/","section":"publication","summary":"Narrative story generation is a challenging problem because it demands the generated sentences with tight semantic connections, which has not been well studied by most existing generative models. To address this problem, we propose a skeleton-based model to promote the coherence of generated stories. Different from traditional models that generate a complete sentence at a stroke, the proposed model first generates the most critical phrases, called skeleton, and then expands the skeleton to a complete and fluent sentence. The skeleton is not manually defined, but learned by a reinforcement learning method. Compared to the state-of-the-art models, our skeleton-based model can generate significantly more coherent text according to human evaluation and automatic evaluation. The G-score is improved by 20.1% in human evaluation.","tags":null,"title":"A Skeleton-Based Model for Promoting Coherence Among Sentences in Narrative Story Generation","type":"publication"},{"authors":["Jingjing Xu","Xuancheng Ren","Junyang Lin","Xu Sun"],"categories":null,"content":"","date":1540944000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611657712,"objectID":"2f4dcb25da5f941e33752fff81167e5c","permalink":"https://jklj077.github.io/publication/2018emnlp-diversity/","publishdate":"2019-12-23T08:04:29.978133Z","relpermalink":"/publication/2018emnlp-diversity/","section":"publication","summary":"Existing text generation methods tend to produce repeated and ”boring” expressions. To tackle this problem, we propose a new text generation model, called Diversity-Promoting Generative Adversarial Network (DP-GAN). The proposed model assigns low reward for repeatedly generated text and high reward for ”novel” and fluent text, encouraging the generator to produce diverse and informative text. Moreover, we propose a novel language-model based discriminator, which can better distinguish novel text from repeated text without the saturation problem compared with existing classifier-based discriminators. The experimental results on review generation and dialogue generation tasks demonstrate that our model can generate substantially more diverse and informative text than existing baselines.","tags":null,"title":"Diversity-Promoting GAN: A Cross-Entropy Based Generative Adversarial Network for Diversified Text Generation","type":"publication"},{"authors":["Fenglin Liu","Xuancheng Ren","Yuanxin Liu","Houfeng Wang","Xu Sun"],"categories":null,"content":"","date":1540944000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611657712,"objectID":"f86fa304ba739bf083d915590793bc8c","permalink":"https://jklj077.github.io/publication/2018emnlp-simnet/","publishdate":"2019-12-23T08:04:29.972123Z","relpermalink":"/publication/2018emnlp-simnet/","section":"publication","summary":"The encode-decoder framework has shown recent success in image captioning. Visual attention, which is good at detailedness, and semantic attention, which is good at comprehensiveness, have been separately proposed to ground the caption on the image. In this paper, we propose the Stepwise Image-Topic Merging Network (simNet) that makes use of the two kinds of attention at the same time. At each time step when generating the caption, the decoder adaptively merges the attentive information in the extracted topics and the image according to the generated context, so that the visual information and the semantic information can be effectively combined. The proposed approach is evaluated on two benchmark datasets and reaches the state-of-the-art performances.","tags":null,"title":"simNet: Stepwise Image-Topic Merging Network for Generating Detailed and Comprehensive Image Captions","type":"publication"},{"authors":["Junyang Lin","Xu Sun","Xuancheng Ren","Shuming Ma","Jinsong Su","Qi Su"],"categories":null,"content":"","date":1534723200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611657712,"objectID":"460eb507a423706392bca660ad3d8183","permalink":"https://jklj077.github.io/publication/2018coling-deconvolution/","publishdate":"2019-12-23T08:04:29.969123Z","relpermalink":"/publication/2018coling-deconvolution/","section":"publication","summary":"A great proportion of sequence-to-sequence (Seq2Seq) models for Neural Machine Translation (NMT) adopt Recurrent Neural Network (RNN) to generate translation word by word following a sequential order. As the studies of linguistics have proved that language is not linear word sequence but sequence of complex structure, translation at each step should be conditioned on the whole target-side context. To tackle the problem, we propose a new NMT model that decodes the sequence with the guidance of its structural prediction of the context of the target sequence. Our model generates translation based on the structural prediction of the target-side context so that the translation can be freed from the bind of sequential order. Experimental results demonstrate that our model is more competitive compared with the state-of-the-art methods, and the analysis reflects that our model is also robust to translating sentences of different lengths and it also reduces repetition with the instruction from the target-side context for decoding.","tags":null,"title":"Deconvolution-Based Global Decoding for Neural Machine Translation","type":"publication"},{"authors":["Yi Zhang","Xu Sun","Shuming Ma","Yang Yang","Xuancheng Ren"],"categories":null,"content":"","date":1534723200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611657712,"objectID":"d42b91696e2d0b6707b81fafe9bb4978","permalink":"https://jklj077.github.io/publication/2018coling-higher/","publishdate":"2019-12-23T08:04:29.966124Z","relpermalink":"/publication/2018coling-higher/","section":"publication","summary":"Existing neural models usually predict the tag of the current token independent of the neighboring tags. The popular LSTM-CRF model considers the tag dependencies between every two consecutive tags. However, it is hard for existing neural models to take longer distance dependencies between tags into consideration. The scalability is mainly limited by the complex model structures and the cost of dynamic programming during training. In our work, we first design a new model called “high order LSTM” to predict multiple tags for the current token which contains not only the current tag but also the previous several tags. We call the number of tags in one prediction as “order”. Then we propose a new method called Multi-Order BiLSTM (MO-BiLSTM) which combines low order and high order LSTMs together. MO-BiLSTM keeps the scalability to high order models with a pruning technique. We evaluate MO-BiLSTM on all-phrase chunking and NER datasets. Experiment results show that MO-BiLSTM achieves the state-of-the-art result in chunking and highly competitive results in two NER datasets.","tags":null,"title":"Does Higher Order LSTM Have Better Accuracy for Segmenting and Labeling Sequence Data?","type":"publication"},{"authors":["Jingjing Xu","Xu Sun","Qi Zeng","Xiaodong Zhang","Xuancheng Ren","Houfeng Wang","Wenjie Li"],"categories":null,"content":"","date":1531612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611657712,"objectID":"077a5cd5e52c08073956f25eba94573f","permalink":"https://jklj077.github.io/publication/2018acl-unpaired/","publishdate":"2019-12-23T08:04:29.963124Z","relpermalink":"/publication/2018acl-unpaired/","section":"publication","summary":"The goal of sentiment-to-sentiment “translation” is to change the underlying sentiment of a sentence while keeping its content. The main challenge is the lack of parallel data. To solve this problem, we propose a cycled reinforcement learning method that enables training on unpaired data by collaboration between a neutralization module and an emotionalization module. We evaluate our approach on two review datasets, Yelp and Amazon. Experimental results show that our approach significantly outperforms the state-of-the-art systems. Especially, the proposed method substantially improves the content preservation performance. The BLEU score is improved from 1.64 to 22.46 and from 0.56 to 14.06 on the two datasets, respectively.","tags":null,"title":"Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach","type":"publication"},{"authors":["Shuming Ma","Xu Sun","Junyang Lin","Xuancheng Ren"],"categories":null,"content":"","date":1531440000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611657712,"objectID":"c0f7ea604f87e3408df054c5ffac80fd","permalink":"https://jklj077.github.io/publication/2018ijcai-hierarchical/","publishdate":"2019-12-23T08:04:29.983094Z","relpermalink":"/publication/2018ijcai-hierarchical/","section":"publication","summary":"Text summarization and sentiment classification both aim to capture the main ideas of the text but at different levels. Text summarization is to describe the text within a few sentences, while sentiment classification can be regarded as a special type of summarization which \"summarizes\" the text into a even more abstract fashion, i.e., a sentiment class. Based on this idea, we propose a hierarchical end-to-end model for joint learning of text summarization and sentiment classification, where the sentiment classification label is treated as the further \"summarization\" of the text summarization output. Hence, the sentiment classification layer is put upon the text summarization layer, and a hierarchical structure is derived. Experimental results on Amazon online reviews datasets show that our model achieves better performance than the strong baseline systems on both abstractive summarization and sentiment classification.","tags":null,"title":"A Hierarchical End-to-End Model for Jointly Improving Text Summarization and Sentiment Classification","type":"publication"},{"authors":["Shuming Ma","Xu Sun","Wei Li","Sujian Li","Wenjie Li","Xuancheng Ren"],"categories":null,"content":"","date":1527811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611657712,"objectID":"b24510fc2c129e54bd4f5d0c13db9702","permalink":"https://jklj077.github.io/publication/2018naacl-query/","publishdate":"2019-12-23T08:04:29.989124Z","relpermalink":"/publication/2018naacl-query/","section":"publication","summary":"Most recent approaches use the sequence-to-sequence model for paraphrase generation. The existing sequence-to-sequence model tends to memorize the words and the patterns in the training dataset instead of learning the meaning of the words. Therefore, the generated sentences are often grammatically correct but semantically improper. In this work, we introduce a novel model based on the encoder-decoder framework, called Word Embedding Attention Network (WEAN). Our proposed model generates the words by querying distributed word representations (i.e. neural word embeddings), hoping to capturing the meaning of the according words. Following previous work, we evaluate our model on two paraphrase-oriented tasks, namely text simplification and short text abstractive summarization. Experimental results show that our model outperforms the sequence-to-sequence baseline by the BLEU score of 6.3 and 5.5 on two English text simplification datasets, and the ROUGE-2 F1 score of 5.7 on a Chinese summarization dataset. Moreover, our model achieves state-of-the-art performances on these three benchmark datasets.","tags":null,"title":"Query and Output: Generating Words by Querying Distributed Word Representations for Paraphrase Generation","type":"publication"},{"authors":["Xuancheng Ren","Xu Sun","Ji Wen","Bingzhen Wei","Weidong Zhan","Zhiyuan Zhang"],"categories":null,"content":"","date":1525651200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611657712,"objectID":"d8c22d07261bae19aa0d074b32d9f350","permalink":"https://jklj077.github.io/publication/2018lrec-building/","publishdate":"2019-12-23T08:04:29.986127Z","relpermalink":"/publication/2018lrec-building/","section":"publication","summary":"Web 2.0 has brought with it numerous user-produced data revealing one's thoughts, experiences, and knowledge, which are a great source for many tasks, such as information extraction, and knowledge base construction. However, the colloquial nature of the texts poses new challenges for current natural language processing techniques, which are more adapt to the formal form of the language. Ellipsis is a common linguistic phenomenon that some words are left out as they are understood from the context, especially in oral utterance, hindering the improvement of dependency parsing, which is of great importance for tasks relied on the meaning of the sentence. In order to promote research in this area, we are releasing a Chinese dependency treebank of 319 weibos, containing 572 sentences with omissions restored and contexts reserved.","tags":null,"title":"Building an Ellipsis-Aware Chinese Dependency Treebank for Web Text","type":"publication"},{"authors":["Xu Sun","Xuancheng Ren","Shuming Ma","Houfeng Wang"],"categories":null,"content":"","date":1501977600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611657712,"objectID":"090e033b89e235e3a8f2db6cb0fea4f6","permalink":"https://jklj077.github.io/publication/2017icml-meprop/","publishdate":"2019-12-23T08:04:30.047125Z","relpermalink":"/publication/2017icml-meprop/","section":"publication","summary":"We propose a simple yet effective technique for neural network learning. The forward propagation is computed as usual. In back propagation, only a small subset of the full gradient is computed to update the model parameters. The gradient vectors are sparsified in such a way that only the top-k elements (in terms of magnitude) are kept. As a result, only k rows or columns (depending on the layout) of the weight matrix are modified, leading to a linear reduction (k divided by the vector dimension) in the computational cost. Surprisingly, experimental results demonstrate that we can update only 1–4% of the weights at each back propagation pass. This does not result in a larger number of training iterations. More interestingly, the accuracy of the resulting models is actually improved rather than degraded, and a detailed analysis is given.","tags":null,"title":"meProp: Sparsified Back Propagation for Accelerated Deep Learning with Reduced Overfitting","type":"publication"}]